<!DOCTYPE html>
<html>
    <head>
        <title>T1A15 Final Working Demo (TensorFlow.js Structure)</title>
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.13.0/dist/tf.min.js"></script>
        
        <style>
            #results {
                white-space: pre-wrap;
                font-family: monospace;
                background: #f4f4f4;
                padding: 10px;
                border: 1px solid #ccc;
            }
            .container {
                display: flex;
                flex-direction: column;
                align-items: center;
                margin-top: 20px;
            }
            #video {
                border: 2px solid #007bff;
                margin-bottom: 10px;
            }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>T1A15 Final Working Demo (TensorFlow.js)</h1>
            <p>This code verifies webcam access and image preprocessing without local files.</p>
            
            <button id="start-webcam">Start Webcam & Verify Preprocessing</button>
            <video id="video" width="320" height="240" autoplay muted></video>
            <canvas id="canvas" width="96" height="96" style="display:none;"></canvas>
            
            <h3>Status:</h3>
            <pre id="results">Click 'Start Webcam' to begin verification...</pre>
        </div>

<script>
    // --- Model and image parameters ---
    const IMAGE_WIDTH = 96;
    const IMAGE_HEIGHT = 96;
    const INFERENCE_INTERVAL_MS = 1000;
    
    // --- Mock classifier function ---
    // This simulates model classification using the correct TensorFlow.js data format (tf.Tensor).
    function mockClassify(inputTensor) {
        // Here, we would load and run the model. For verification, we just confirm data shape.
        const output = {
            success: true,
            status: `Data Shape Verified: ${inputTensor.shape}`,
            dtype: `Data Type Verified: ${inputTensor.dtype}`
        };
        return output;
    }


    document.getElementById('start-webcam').addEventListener('click', async () => {
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const results = document.getElementById('results');

        // 1. Request camera access
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            results.textContent = 'Error: Webcam access not supported by your browser.';
            return;
        }
        
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { width: 320, height: 240 } 
            });
            video.srcObject = stream;
        } catch (err) {
            results.textContent = 'Error accessing webcam: ' + err.name + '. Please ensure your browser has permission.';
            return;
        }
        
        await new Promise(resolve => video.onloadedmetadata = resolve);

        results.textContent = 'Webcam started. Verifying data pipeline...';

        // 2. Start Verification Loop
        const inferenceInterval = setInterval(() => {
            // Draw current video frame to the canvas
            ctx.drawImage(video, 0, 0, IMAGE_WIDTH, IMAGE_HEIGHT);
            
            // 3. Convert Canvas Image Data to a TensorFlow.js Tensor (Grayscale, Normalized)
            const imageData = ctx.getImageData(0, 0, IMAGE_WIDTH, IMAGE_HEIGHT);

            // Create a temporary array for the grayscale data
            const grayscaleData = new Float32Array(IMAGE_WIDTH * IMAGE_HEIGHT);
            
            for (let i = 0, j = 0; i < imageData.data.length; i += 4, j++) {
                const r = imageData.data[i];
                const g = imageData.data[i + 1];
                const b = imageData.data[i + 2];
                
                // Calculate weighted Grayscale value (0-255)
                const grayscale = (r * 0.299) + (g * 0.587) + (b * 0.114);
                
                // Normalize (0-255 -> 0-1)
                grayscaleData[j] = grayscale / 255.0;
            }

            // Create the final tf.Tensor (96x96x1 shape)
            const inputTensor = tf.tensor(grayscaleData, [IMAGE_WIDTH, IMAGE_HEIGHT, 1], 'float32');

            // 4. Run Mock Classification and output results
            const verificationResult = mockClassify(inputTensor);

            results.textContent = JSON.stringify(verificationResult, null, 2);
            
            // Crucial: Dispose of the tensor memory
            tf.dispose(inputTensor);

        }, INFERENCE_INTERVAL_MS);
    });
</script>
    </body>
</html>
